# CritterCatcherAI Configuration

# Paths (container paths - map these in docker-compose.yml)
paths:
  downloads: /data/downloads
  sorted: /data/sorted
  face_encodings: /data/faces/encodings.pkl

# Ring doorbell settings
ring:
  # How many hours back to download videos
  download_hours: 24
  
  # Optional: limit number of videos per run (null for no limit)
  download_limit: null

# Detection settings
detection:
  # YOLO model selection: yolov8n (nano - fastest), yolov8s (small), yolov8m (medium), 
  # yolov8l (large), yolov8x (extra large - most accurate)
  yolo_model: yolov8n
  
  # Object labels to detect - MUST match YOLO COCO classes
  # Available COCO classes: person, bicycle, car, motorcycle, airplane, bus, train, truck, boat,
  # traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep,
  # cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee,
  # skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard,
  # tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich,
  # orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed,
  # dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven,
  # toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush
  object_labels:
    - bird       # Catches all birds (crows, robins, wrens, finches, etc.)
    - cat        # Includes outdoor/feral cats and potentially small mammals
    - dog        # Dogs and potentially foxes
    - person     # People including delivery persons
    - car
    - bicycle
    - truck      # Delivery trucks
  
  # Confidence threshold for object detection (0.0-1.0)
  # YOLO performs well at 0.25-0.5. Lower = more detections, higher = more accuracy
  confidence_threshold: 0.35
  
  # Number of frames to analyze for object detection (3-20)
  # More frames = more accurate but slower processing
  object_frames: 5
  
  # Face recognition tolerance (0.0-1.0)
  # Lower = more strict matching
  # Higher = more lenient matching
  face_tolerance: 0.6
  
  # Number of frames to analyze for face recognition (5-30)
  # More frames = better chance of recognition but slower
  face_frames: 10
  
  # Face detection model: "hog" (fast, CPU-friendly) or "cnn" (accurate, GPU recommended)
  face_model: hog
  
  # Priority for sorting: "people" or "objects"
  # "people" = prioritize face recognition over object detection
  # "objects" = prioritize object detection over face recognition
  priority: people
  
  # Discovery mode: automatically find objects not in your tracked list
  # Note: YOLO only detects its 80 COCO classes, but discovery mode will alert you
  # to other COCO objects appearing in videos (e.g., horse, cow, bear, etc.)
  discovery_mode: true
  
  # Confidence threshold for discovering new objects (higher than regular threshold)
  discovery_threshold: 0.40
  
  # Objects to ignore (blacklist) - YOLO COCO classes to not track
  ignored_labels:
    - potted plant
    - chair
    - bench
    - traffic light
  
  # Discovered objects pending user confirmation (managed by system)
  discovered_labels: []

# Specialized species detection (Stage 2 - fine-grained classification)
specialized_detection:
  # Enable specialized species classifiers
  enabled: false  # Set to true once models are trained
  
  # Target species definitions
  species: []
    # Example configuration (uncomment and modify when ready):
    # - name: hedgehog
    #   parent_yolo_class: [cat, dog]  # YOLO classes to check
    #   model_path: /data/models/hedgehog_classifier.pt
    #   confidence_threshold: 0.75
    # 
    # - name: finch
    #   parent_yolo_class: [bird]
    #   model_path: /data/models/finch_classifier.pt
    #   confidence_threshold: 0.70
    #   sub_classifiers:
    #     - name: goldfinch
    #       model_path: /data/models/goldfinch_classifier.pt
    #       confidence_threshold: 0.65
  
  # Clip extraction settings
  clip_extraction:
    enabled: false  # Enable clip extraction mode
    padding_seconds: 10  # Seconds before/after detection to include
    merge_overlapping: true  # Merge nearby detections into one clip
    auto_delete_non_matches: false  # DELETE non-matching videos (CAUTION!)
    output_path: /data/clips  # Extracted clips for Plex
  
  # Training settings
  training:
    data_augmentation: true
    validation_split: 0.2
    epochs: 50
    batch_size: 32
    learning_rate: 0.001

# Application settings
# Run once and exit, or run continuously
run_once: false

# Interval between processing runs (in minutes)
interval_minutes: 60
